✅ Step 1: Get to Know Your Data and Robot
What to Do:

Open the data.toml file to find important robot details like:

Wheelbase (distance between front and rear wheels)

Track width (distance between left and right wheels)

Open the MCAP file and check what types of sensor data it contains.

Focus on these key data types:

Drive Feedback: Gives steering angle and speed

IMU: Provides acceleration and rotation rates

Ground Truth: Tells the actual position and orientation of the robot (used for checking accuracy)

Why This Matters:
You need to understand what your robot looks like and how it moves. This step helps you figure out what data you'll use to estimate the robot’s position and what data you'll use to check if your estimation is accurate.

✅ Step 2: Decide What the Filter Should Estimate
What to Do:

Decide what you want to track. A common choice:

X position

Y position

Heading (yaw)

Speed

Describe how the robot moves, using a simple bicycle model based on its steering and speed.

Describe what the sensors measure:

IMU gives yaw rate and acceleration

Drive feedback can also help estimate speed

Why This Matters:
You need to tell the filter how your robot moves and what the sensors tell you. This helps the filter combine movement and sensor data to estimate position more accurately.

✅ Step 3: Build the Filter Logic
What to Do:

Set up the starting values for position, speed, and uncertainty.

For each step:

Predict the next position based on steering and speed.

Correct the prediction using IMU data.

Handle any necessary math for how predictions and corrections are calculated.

Why This Matters:
This step is the brain of the system. It combines your robot’s model and real sensor data to guess where the robot is and correct that guess over time.

✅ Step 4: Get the Data in Sync
What to Do:

Read the MCAP file and pull out the drive feedback, IMU, and ground truth data.

Make sure the timestamps of all sensors line up correctly.

If one sensor updates faster than another, interpolate or adjust the timing to match.

Why This Matters:
You can’t combine data from different sensors unless they’re lined up in time. This step ensures you’re using the right sensor readings at the right moments.

✅ Step 5: Run the Filter with Real Data
What to Do:

Go through the data in time order.

At each time step:

Use drive feedback to predict the robot’s new position.

Use IMU data to correct the position.

Save the estimated result.

Why This Matters:
This is where your filter does its job—tracking the robot’s movement through real data, step by step.

✅ Step 6: Check How Well It Worked
What to Do:

Compare your estimated positions to the ground truth data.

Measure the differences:

RMSE (overall error)

Final position error (where the robot ended up)

(Optional) Plot both paths to see how closely they match.

Why This Matters:
You want to see if your filter is working well. Comparing it to real position data helps you understand how accurate it is.

✅ Step 7: Visualize the Results (Optional)
What to Do:

Create plots that show:

The path estimated by the filter

The actual path from ground truth

Error over time

Why This Matters:
A good visual makes your work easier to understand. It also helps you catch any problems more quickly.
